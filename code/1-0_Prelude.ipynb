{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1-0 - Prelude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df.iloc[:712, :]\n",
    "\n",
    "df_train = df_train.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "\n",
    "age_mean = df_train['Age'].mean()\n",
    "df_train['Age'] = df_train['Age'].fillna(age_mean)\n",
    "df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df_train[features].values)\n",
    "y_train = df_train['Survived'].values\n",
    "y_train_onehot = pd.get_dummies(df_train['Survived']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df.iloc[712:, :]\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "\n",
    "df_test['Age'] = df_test['Age'].fillna(age_mean)\n",
    "df_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "X_test = scaler.transform(df_test[features].values)\n",
    "y_test = df_test['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "\n",
      "accuracy 0.832402234637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, verbose=3)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = model.predict(X_test)\n",
    "print \"\\naccuracy\", np.sum(y_prediction == y_test) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.685 accuracy 0.64 loop 0\n",
      "loss 0.683 accuracy 0.642 loop 1\n",
      "loss 0.681 accuracy 0.695 loop 5\n",
      "loss 0.675 accuracy 0.712 loop 8\n",
      "loss 0.673 accuracy 0.737 loop 44\n",
      "loss 0.661 accuracy 0.739 loop 47\n",
      "loss 0.658 accuracy 0.715 loop 297\n",
      "loss 0.652 accuracy 0.77 loop 514\n",
      "\n",
      "time taken 8.20281195641 seconds\n"
     ]
    }
   ],
   "source": [
    "min_loss = 1000\n",
    "best_weights = ()\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i in xrange(1000):\n",
    "    W = np.random.rand(2, 6) / 10\n",
    "    b = np.random.rand(2,) / 10\n",
    "\n",
    "    scores = []\n",
    "    loss = 0\n",
    "    \n",
    "    for j in xrange(X_train.shape[0]):\n",
    "        result = np.dot(W, X_train[j]) + b\n",
    "        result = softmax(result)\n",
    "        scores.append(list(result))\n",
    "        \n",
    "        label_index = np.argmax(y_train_onehot[j])\n",
    "        loss += -np.log(result[label_index])\n",
    "\n",
    "    loss = loss / float(X_train.shape[0])\n",
    "    y_prediction = np.argmax(np.array(scores), axis=1)\n",
    "    accuracy = np.sum(y_prediction == y_train) / float(len(y_train))\n",
    "    \n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_weights = (W, b)\n",
    "        print 'loss %s accuracy %s loop %s' % (round(loss, 3), round(accuracy, 3), i)\n",
    "\n",
    "print '\\ntime taken %s seconds' % str(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.810055865922\n"
     ]
    }
   ],
   "source": [
    "W, b = best_weights\n",
    "scores = []\n",
    "\n",
    "for j in xrange(X_test.shape[0]):\n",
    "    result = np.dot(W, X_test[j]) + b\n",
    "    result = softmax(result)\n",
    "    scores.append(list(result))\n",
    "\n",
    "y_prediction = np.argmax(np.array(scores), axis=1)\n",
    "\n",
    "print \"accuracy\", np.sum(y_prediction == y_test) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.682 accuracy 0.61 loop 0\n",
      "loss 0.679 accuracy 0.757 loop 5\n",
      "loss 0.678 accuracy 0.657 loop 8\n",
      "loss 0.675 accuracy 0.787 loop 15\n",
      "loss 0.67 accuracy 0.676 loop 29\n",
      "loss 0.668 accuracy 0.633 loop 333\n",
      "loss 0.663 accuracy 0.702 loop 362\n",
      "loss 0.663 accuracy 0.708 loop 590\n",
      "\n",
      "time taken 9.62385892868 seconds\n"
     ]
    }
   ],
   "source": [
    "min_loss = 1000\n",
    "best_weights = ()\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i in xrange(1000):\n",
    "    W_1 = np.random.rand(100, 6) / 10\n",
    "    b_1 = np.random.rand(100,) / 10\n",
    "    W_2 = np.random.rand(2, 100) / 10\n",
    "    b_2 = np.random.rand(2,) / 10\n",
    "    \n",
    "    scores = []\n",
    "    loss = 0\n",
    "\n",
    "    for j in xrange(X_train.shape[0]):\n",
    "        result = np.dot(W_1, X_train[j]) + b_1\n",
    "        result = np.dot(W_2, result) + b_2\n",
    "        result = softmax(result)\n",
    "        scores.append(list(result))\n",
    "        \n",
    "        label_index = np.argmax(y_train_onehot[j])\n",
    "        loss += -np.log(result[label_index])\n",
    "\n",
    "    loss = loss / float(X_train.shape[0])\n",
    "    y_prediction = np.argmax(np.array(scores), axis=1)\n",
    "    accuracy = np.sum(y_prediction == y_train) / float(len(y_train))\n",
    "        \n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_weights = (W_1, b_1, W_2, b_2)\n",
    "        print 'loss %s accuracy %s loop %s' % (round(loss, 3), round(accuracy, 3), i)\n",
    "\n",
    "print '\\ntime taken %s seconds' % str(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.670391061453\n"
     ]
    }
   ],
   "source": [
    "W_1, b_1, W_2, b_2 = best_weights\n",
    "scores = []\n",
    "\n",
    "for j in xrange(X_test.shape[0]):\n",
    "    result = np.dot(W_1, X_test[j]) + b_1\n",
    "    result = np.dot(W_2, result) + b_2\n",
    "    result = softmax(result)\n",
    "    scores.append(list(result))\n",
    "    \n",
    "y_prediction = np.argmax(np.array(scores), axis=1)\n",
    "\n",
    "print \"accuracy\", np.sum(y_prediction == y_test) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.797 accuracy 0.287 loop 0\n",
      "loss 0.753 accuracy 0.296 loop 1\n",
      "loss 0.752 accuracy 0.285 loop 2\n",
      "loss 0.695 accuracy 0.39 loop 4\n",
      "loss 0.656 accuracy 0.705 loop 5\n",
      "loss 0.644 accuracy 0.709 loop 7\n",
      "loss 0.642 accuracy 0.705 loop 12\n",
      "loss 0.633 accuracy 0.709 loop 19\n",
      "loss 0.621 accuracy 0.721 loop 79\n",
      "loss 0.621 accuracy 0.715 loop 130\n",
      "loss 0.619 accuracy 0.728 loop 501\n",
      "loss 0.618 accuracy 0.715 loop 956\n",
      "\n",
      "time taken 13.7536799908 seconds\n"
     ]
    }
   ],
   "source": [
    "min_loss = 1000\n",
    "best_weights = ()\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i in xrange(1000):\n",
    "    W_1 = np.random.rand(100, 6) / 10\n",
    "    b_1 = np.random.rand(100,) / 10\n",
    "    W_2 = np.random.rand(100, 100) / 10\n",
    "    b_2 = np.random.rand(100,) / 10\n",
    "    W_3 = np.random.rand(2, 100) / 10\n",
    "    b_3 = np.random.rand(2,) / 10\n",
    "    \n",
    "    scores = []\n",
    "    loss = 0\n",
    "\n",
    "    for j in xrange(X_train.shape[0]):\n",
    "        result = np.dot(W_1, X_train[j]) + b_1\n",
    "        result = np.dot(W_2, result) + b_2\n",
    "        result = np.dot(W_3, result) + b_3\n",
    "        result = softmax(result)\n",
    "        scores.append(list(result))\n",
    "        \n",
    "        label_index = np.argmax(y_train_onehot[j])\n",
    "        loss += -np.log(result[label_index])\n",
    "        \n",
    "    loss = loss / float(X_train.shape[0])\n",
    "    y_prediction = np.argmax(np.array(scores), axis=1)\n",
    "    accuracy = np.sum(y_prediction == y_train) / float(len(y_train))          \n",
    "        \n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_weights = (W_1, b_1, W_2, b_2, W_3, b_3)\n",
    "        print 'loss %s accuracy %s loop %s' % (round(loss, 3), round(accuracy, 3), i)\n",
    "\n",
    "print '\\ntime taken %s seconds' % str(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.703910614525\n"
     ]
    }
   ],
   "source": [
    "W_1, b_1, W_2, b_2, W_3, b_3 = best_weights\n",
    "scores = []\n",
    "\n",
    "for j in xrange(X_test.shape[0]):\n",
    "    result = np.dot(W_1, X_test[j]) + b_1\n",
    "    result = np.dot(W_2, result) + b_2\n",
    "    result = np.dot(W_3, result) + b_3    \n",
    "    result = softmax(result)\n",
    "    scores.append(list(result))\n",
    "    \n",
    "y_prediction = np.argmax(np.array(scores), axis=1)\n",
    "\n",
    "print \"accuracy\", np.sum(y_prediction == y_test) / float(len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
